import os
import requests
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
import xml.etree.ElementTree as ET
from datetime import datetime
import tempfile
import time

# âœ… ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆæœ€åˆã«1å›ã ã‘å‘¼ã³å‡ºã™ï¼‰
st.set_page_config(
    page_title="RT-LitSearch - æ•´å½¢å¤–ç§‘è«–æ–‡è¦ç´„",
    page_icon="ğŸ¥",
    layout="wide",
)

# âœ… ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆCSSï¼‰: set_page_config ã®å¾Œã«ç½®ã
st.markdown(
    """
    <style>
    .block-container {
        padding-left: 1rem;
        padding-right: 1rem;
        padding-top: 1rem;
        padding-bottom: 2rem;
    }
    h1, h2, h3 {
        font-size: 1.4rem;
        line-height: 1.6rem;
    }
    button[kind="primary"] {
        font-size: 1.2rem !important;
        padding: 1rem 2rem !important;
    }
    .stMarkdown {
        background-color: #f9f9f9;
        padding: 1rem;
        border-radius: 0.8rem;
        margin-bottom: 1rem;
    }
    a {
        color: #0066cc !important;
        font-weight: bold;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# âœ… ç’°å¢ƒå¤‰æ•°
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
NIH_EMAIL = os.getenv("NIH_EMAIL")


class PubMedSearcher:
    def __init__(self):
        self.base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"
        self.email = NIH_EMAIL or ""

    def search_papers(self, query, max_results=5):
        """PubMedã§è«–æ–‡ã‚’æ¤œç´¢"""
        try:
            search_url = f"{self.base_url}esearch.fcgi"
            search_params = {
                "db": "pubmed",
                "term": query,
                "retmax": max_results,
                "sort": "pub_date",
                "retmode": "xml"
            }
            if self.email:
                search_params["email"] = self.email

            response = requests.get(search_url, params=search_params)
            response.raise_for_status()

            root = ET.fromstring(response.content)
            pmids = [id_elem.text for id_elem in root.findall(".//Id")]
            if not pmids:
                return []
            return self._fetch_paper_details(pmids)
        except Exception as e:
            print(f"PubMedæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def _fetch_paper_details(self, pmids):
        """PMIDã‹ã‚‰è«–æ–‡è©³ç´°ã‚’å–å¾—"""
        try:
            fetch_url = f"{self.base_url}efetch.fcgi"
            fetch_params = {
                "db": "pubmed",
                "id": ",".join(pmids),
                "retmode": "xml"
            }
            if self.email:
                fetch_params["email"] = self.email

            response = requests.get(fetch_url, params=fetch_params)
            response.raise_for_status()

            root = ET.fromstring(response.content)
            papers = []
            for article in root.findall(".//PubmedArticle"):
                paper = self._parse_article(article)
                if paper:
                    papers.append(paper)
            return papers
        except Exception as e:
            print(f"è«–æ–‡è©³ç´°å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def _parse_article(self, article):
        """XMLè¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‘ãƒ¼ã‚¹"""
        try:
            pmid_elem = article.find(".//PMID")
            pmid = pmid_elem.text if pmid_elem is not None else ""
            title_elem = article.find(".//ArticleTitle")
            title = title_elem.text if title_elem is not None else "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜"
            authors = []
            for author in article.findall(".//Author")[:5]:
                last_name = author.find("LastName")
                first_name = author.find("ForeName")
                if last_name is not None:
                    name = last_name.text
                    if first_name is not None:
                        name += f" {first_name.text}"
                    authors.append(name)
            journal_elem = article.find(".//Journal/Title")
            journal = journal_elem.text if journal_elem is not None else "é›‘èªŒåä¸æ˜"
            year_elem = article.find(".//PubDate/Year")
            year = year_elem.text if year_elem is not None else "å¹´ä¸æ˜"
            abstract_elem = article.find(".//Abstract/AbstractText")
            abstract = abstract_elem.text if abstract_elem is not None else ""
            return {
                "pmid": pmid,
                "title": title,
                "authors": authors,
                "journal": journal,
                "year": year,
                "abstract": abstract,
                "url": f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/"
            }
        except Exception as e:
            print(f"è¨˜äº‹ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
            return None


class PaperSummarizer:
    def __init__(self):
        if not OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        self.client = OpenAI(api_key=OPENAI_API_KEY)

    def summarize_paper(self, paper):
        """è«–æ–‡ã‚’æ—¥æœ¬èªã§è¦ç´„"""
        try:
            prompt = f"""
ä»¥ä¸‹ã®åŒ»å­¦è«–æ–‡ã«ã¤ã„ã¦ã€æ•´å½¢å¤–ç§‘ã‚¯ãƒªãƒ‹ãƒƒã‚¯ã®åŒ»å¸«ãƒ»ç†å­¦ç™‚æ³•å£«å‘ã‘ã«300-500å­—ã®æ—¥æœ¬èªè¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã‚¿ã‚¤ãƒˆãƒ«: {paper['title']}
è‘—è€…: {', '.join(paper['authors'][:3])}
é›‘èªŒ: {paper['journal']} ({paper['year']})
ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ: {paper['abstract'][:1000]}

è¦ç´„ã®æ§‹æˆ:
1. èƒŒæ™¯ãƒ»ç›®çš„ï¼ˆ1-2æ–‡ï¼‰
2. æ–¹æ³•ãƒ»ä»‹å…¥ï¼ˆ1-2æ–‡ï¼‰
3. çµæœï¼ˆ2-3æ–‡ï¼‰
4. è‡¨åºŠçš„ç¤ºå”†ï¼ˆ1-2æ–‡ï¼‰
5. é™ç•Œãƒ»æ³¨æ„ç‚¹ï¼ˆ1æ–‡ï¼‰
"""
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯æ•´å½¢å¤–ç§‘ãƒ»ãƒªãƒãƒ“ãƒªåˆ†é‡ã®è«–æ–‡è¦ç´„å°‚é–€å®¶ã§ã™ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.3
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return "è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"


def search_and_summarize(query, max_results):
    if not query.strip():
        return "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", None

    progress_bar = st.progress(0.0)
    status_text = st.empty()
    status_text.text("PubMedã§è«–æ–‡ã‚’æ¤œç´¢ä¸­...")
    progress_bar.progress(0.10)

    searcher = PubMedSearcher()
    papers = searcher.search_papers(query, max_results)
    if not papers:
        status_text.text("è©²å½“ã™ã‚‹è«–æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return [], None

    progress_bar.progress(0.30)

    summarizer = PaperSummarizer()
    results = []
    for i, paper in enumerate(papers):
        status_text.text(f"è«–æ–‡ {i+1}/{len(papers)} ã‚’è¦ç´„ä¸­...")
        pct = (30.0 + 60.0 * (i + 1) / len(papers)) / 100.0
        pct = max(0.0, min(pct, 1.0))
        progress_bar.progress(pct)
        summary = summarizer.summarize_paper(paper)
        result = {
            "title": paper["title"],
            "authors": paper["authors"],
            "journal": paper["journal"],
            "year": paper["year"],
            "url": paper["url"],
            "summary": summary
        }
        results.append(result)
        time.sleep(1)

    markdown_file = generate_markdown_file(results, query)
    progress_bar.progress(1.0)
    status_text.text("æ¤œç´¢ãƒ»è¦ç´„ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    return results, markdown_file


def generate_markdown_file(results, query):
    try:
        markdown_content = f"""# RT-LitSearch æ¤œç´¢çµæœ

**æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:** {query}  
**æ¤œç´¢æ—¥æ™‚:** {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}  
**ä»¶æ•°:** {len(results)}ä»¶

---
"""
        for i, result in enumerate(results, 1):
            authors_text = ", ".join(result["authors"][:3])
            if len(result["authors"]) > 3:
                authors_text += " ã»ã‹"
            markdown_content += f"""## {i}. {result["title"]}

**è‘—è€…:** {authors_text}  
**é›‘èªŒ:** {result["journal"]} ({result["year"]})  
**PubMed URL:** {result["url"]}

### ğŸ“‹ è‡¨åºŠå‘ã‘è¦ç´„
{result["summary"]}

---
"""
        temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8')
        temp_file.write(markdown_content)
        temp_file.close()
        return temp_file.name
    except Exception as e:
        print(f"Markdownãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None


def main():
    st.markdown("""
    <div style="text-align: center; color: #2c5aa0; margin-bottom: 30px;">
        <h1>ğŸ¥ RT-LitSearch</h1>
        <p style="font-size: 18px;">æ•´å½¢å¤–ç§‘ã‚¯ãƒªãƒ‹ãƒƒã‚¯å‘ã‘ PubMedè«–æ–‡è¦ç´„ã‚¢ãƒ—ãƒª</p>
    </div>
    """, unsafe_allow_html=True)

    col1, col2 = st.columns([3, 1])
    with col1:
        query = st.text_area(
            "ğŸ” æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
            placeholder="ä¾‹: è†OA é‹å‹•ç™‚æ³•, shoulder impingement exercise, lumbar disc herniation",
            height=100
        )
    with col2:
        max_results = st.slider("ğŸ“Š å–å¾—ä»¶æ•°", min_value=1, max_value=10, value=5, step=1)

    if st.button("ğŸš€ æ¤œç´¢ãƒ»è¦ç´„å®Ÿè¡Œ", type="primary"):
        if not query.strip():
            st.error("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            results, markdown_file = search_and_summarize(query, max_results)
            if results:
                st.markdown(f"### ğŸ“„ æ¤œç´¢çµæœ: \"{query}\" ({len(results)}ä»¶)")
                for i, result in enumerate(results, 1):
                    with st.expander(f"{i}. {result['title']}", expanded=True):
                        authors_text = ", ".join(result["authors"][:3])
                        if len(result["authors"]) > 3:
                            authors_text += " ã»ã‹"
                        st.markdown(f"""
                        **è‘—è€…:** {authors_text}  
                        **é›‘èªŒ:** {result["journal"]} ({result["year"]})  
                        **PubMed URL:** [{result["url"]}]({result["url"]})

                        ### ğŸ“‹ è‡¨åºŠå‘ã‘è¦ç´„
                        {result["summary"]}
                        """)
                if markdown_file:
                    with open(markdown_file, 'r', encoding='utf-8') as f:
                        markdown_content = f.read()
                    st.download_button(
                        label="ğŸ’¾ Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=markdown_content,
                        file_name=f"RT-LitSearch_{query.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M')}.md",
                        mime="text/markdown"
                    )

    st.markdown("""
    ---
    ### ğŸ’¡ ä½¿ã„æ–¹
    1. **æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›**ï¼ˆæ—¥æœ¬èªãƒ»è‹±èªã©ã¡ã‚‰ã§ã‚‚å¯ï¼‰
    2. **å–å¾—ä»¶æ•°ã‚’é¸æŠ**ï¼ˆ1-10ä»¶ï¼‰
    3. **ã€Œæ¤œç´¢ãƒ»è¦ç´„å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯**
    4. **çµæœã‚’ç¢ºèª**ã—ã€å¿…è¦ã«å¿œã˜ã¦Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    """)


if __name__ == "__main__":
    if not OPENAI_API_KEY:
        st.error("âš ï¸ OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.info("ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œã®å ´åˆã¯.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    main()
